{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Datathon FIAP - Passos M√°gicos\n",
    "## Modelo Preditivo de Risco de Defasagem\n",
    "\n",
    "Este notebook desenvolve um modelo de Machine Learning para identificar alunos em risco de defasagem educacional, utilizando os indicadores do PEDE dos anos 2022, 2023 e 2024.\n",
    "\n",
    "**Objetivo:** Criar um modelo preditivo que identifique padr√µes nos indicadores que permitam prever alunos em risco de defasagem escolar.\n",
    "\n",
    "**Autor:** Leandro Leme Crespo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar o reposit√≥rio do GitHub (executar apenas no Google Colab)\n",
    "!git clone https://github.com/LeandroCrespo/datathon-passos-magicos.git\n",
    "print('‚úÖ Reposit√≥rio clonado com sucesso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar bibliotecas necess√°rias\n",
    "!pip install openpyxl scikit-learn imbalanced-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print('‚úÖ Bibliotecas importadas com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Prepara√ß√£o dos Dados (3 Anos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados (do reposit√≥rio GitHub)\n",
    "CAMINHO_ARQUIVO = '/content/datathon-passos-magicos/data/BASE_DE_DADOS_PEDE_2024_DATATHON.xlsx'\n",
    "\n",
    "xlsx = pd.ExcelFile(CAMINHO_ARQUIVO)\n",
    "df_2022 = pd.read_excel(xlsx, sheet_name='PEDE2022')\n",
    "df_2023 = pd.read_excel(xlsx, sheet_name='PEDE2023')\n",
    "df_2024 = pd.read_excel(xlsx, sheet_name='PEDE2024')\n",
    "\n",
    "print(f'üìä Dados carregados:')\n",
    "print(f'   PEDE 2022: {df_2022.shape[0]:,} alunos')\n",
    "print(f'   PEDE 2023: {df_2023.shape[0]:,} alunos')\n",
    "print(f'   PEDE 2024: {df_2024.shape[0]:,} alunos')\n",
    "print(f'   TOTAL: {df_2022.shape[0] + df_2023.shape[0] + df_2024.shape[0]:,} registros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para padronizar colunas\n",
    "def padronizar_colunas(df, ano):\n",
    "    df = df.copy()\n",
    "    mapeamento = {}\n",
    "    \n",
    "    # Mapeamento espec√≠fico por ano para INDE e PEDRA\n",
    "    if ano == '2022':\n",
    "        mapeamento['INDE 22'] = 'INDE'\n",
    "        mapeamento['Pedra 22'] = 'PEDRA'\n",
    "    elif ano == '2023':\n",
    "        mapeamento['INDE 2023'] = 'INDE'\n",
    "        mapeamento['Pedra 2023'] = 'PEDRA'\n",
    "    elif ano == '2024':\n",
    "        mapeamento['INDE 2024'] = 'INDE'\n",
    "        mapeamento['Pedra 2024'] = 'PEDRA'\n",
    "    \n",
    "    # Mapeamento gen√©rico para outras colunas\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if col in mapeamento:\n",
    "            continue\n",
    "        if col_lower == 'idade' or col_lower.startswith('idade'):\n",
    "            mapeamento[col] = 'IDADE'\n",
    "        elif col_lower == 'iaa':\n",
    "            mapeamento[col] = 'IAA'\n",
    "        elif col_lower == 'ieg':\n",
    "            mapeamento[col] = 'IEG'\n",
    "        elif col_lower == 'ips':\n",
    "            mapeamento[col] = 'IPS'\n",
    "        elif col_lower == 'ipp':\n",
    "            mapeamento[col] = 'IPP'\n",
    "        elif col_lower == 'ida':\n",
    "            mapeamento[col] = 'IDA'\n",
    "        elif col_lower == 'ipv':\n",
    "            mapeamento[col] = 'IPV'\n",
    "        elif col_lower == 'ian':\n",
    "            mapeamento[col] = 'IAN'\n",
    "        elif 'defas' in col_lower:\n",
    "            mapeamento[col] = 'DEFASAGEM'\n",
    "    \n",
    "    df = df.rename(columns=mapeamento)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]  # Remover colunas duplicadas\n",
    "    df['ANO'] = int(ano)\n",
    "    return df\n",
    "\n",
    "# Padronizar os 3 anos\n",
    "df_2022_pad = padronizar_colunas(df_2022, '2022')\n",
    "df_2023_pad = padronizar_colunas(df_2023, '2023')\n",
    "df_2024_pad = padronizar_colunas(df_2024, '2024')\n",
    "\n",
    "print('‚úÖ Colunas padronizadas com sucesso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas comuns\n",
    "colunas = ['ANO', 'INDE', 'IAA', 'IEG', 'IPS', 'IPP', 'IDA', 'IPV', 'IAN', 'DEFASAGEM']\n",
    "\n",
    "def selecionar_colunas(df, colunas):\n",
    "    return df[[c for c in colunas if c in df.columns]].copy()\n",
    "\n",
    "df_2022_sel = selecionar_colunas(df_2022_pad, colunas)\n",
    "df_2023_sel = selecionar_colunas(df_2023_pad, colunas)\n",
    "df_2024_sel = selecionar_colunas(df_2024_pad, colunas)\n",
    "\n",
    "# Combinar os 3 anos\n",
    "df_unificado = pd.concat([df_2022_sel, df_2023_sel, df_2024_sel], ignore_index=True)\n",
    "\n",
    "# Converter para num√©rico\n",
    "colunas_numericas = ['INDE', 'IAA', 'IEG', 'IPS', 'IPP', 'IDA', 'IPV', 'IAN', 'DEFASAGEM']\n",
    "for col in colunas_numericas:\n",
    "    if col in df_unificado.columns:\n",
    "        df_unificado[col] = pd.to_numeric(df_unificado[col], errors='coerce')\n",
    "\n",
    "print(f'‚úÖ DataFrame unificado: {len(df_unificado):,} registros')\n",
    "print(f'\\nDistribui√ß√£o por ano:')\n",
    "print(df_unificado['ANO'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defini√ß√£o da Vari√°vel Alvo (Risco de Defasagem)\n",
    "\n",
    "A coluna **DEFASAGEM** representa a diferen√ßa entre a fase atual do aluno e a fase ideal para sua idade:\n",
    "- **Valores negativos**: Aluno est√° adiantado (fase acima do esperado)\n",
    "- **Zero**: Aluno est√° na fase correta para sua idade\n",
    "- **Valores positivos**: Aluno est√° atrasado/defasado (fase abaixo do esperado)\n",
    "\n",
    "**Crit√©rio de risco:** Consideramos em risco os alunos com DEFASAGEM > 0 (atrasados em rela√ß√£o √† fase ideal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir vari√°vel alvo: aluno em risco de defasagem\n",
    "# Crit√©rio: defasagem > 0 (aluno est√° atrasado em rela√ß√£o √† fase ideal)\n",
    "\n",
    "df_unificado['RISCO_DEFASAGEM'] = (df_unificado['DEFASAGEM'] > 0).astype(int)\n",
    "\n",
    "print('üìä Distribui√ß√£o da vari√°vel alvo (RISCO_DEFASAGEM):')\n",
    "print(df_unificado['RISCO_DEFASAGEM'].value_counts())\n",
    "print(f'\\nPercentual em risco: {df_unificado[\"RISCO_DEFASAGEM\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gr√°fico 1: Distribui√ß√£o da vari√°vel alvo\n",
    "cores = ['#2ecc71', '#e74c3c']\n",
    "labels = ['Sem risco (0)', 'Com risco (1)']\n",
    "valores = df_unificado['RISCO_DEFASAGEM'].value_counts().sort_index()\n",
    "axes[0].pie(valores, labels=labels, colors=cores, autopct='%1.1f%%', startangle=90, explode=[0, 0.1])\n",
    "axes[0].set_title('Distribui√ß√£o da Vari√°vel Alvo', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Gr√°fico 2: Risco por ano\n",
    "risco_ano = df_unificado.groupby('ANO')['RISCO_DEFASAGEM'].mean() * 100\n",
    "bars = axes[1].bar(risco_ano.index.astype(str), risco_ano.values, color='#e74c3c', edgecolor='black')\n",
    "axes[1].set_title('Percentual de Alunos em Risco por Ano', fontweight='bold', fontsize=14)\n",
    "axes[1].set_xlabel('Ano')\n",
    "axes[1].set_ylabel('% em Risco')\n",
    "for bar, val in zip(bars, risco_ano.values):\n",
    "    axes[1].annotate(f'{val:.1f}%', (bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                     textcoords='offset points', xytext=(0, 5), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('distribuicao_risco.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar features para o modelo\n",
    "features = ['IAN', 'IDA', 'IEG', 'IAA', 'IPS', 'IPP', 'IPV', 'INDE']\n",
    "features_existentes = [f for f in features if f in df_unificado.columns]\n",
    "\n",
    "print(f'Features dispon√≠veis: {features_existentes}')\n",
    "\n",
    "# Preparar dados para o modelo\n",
    "df_modelo = df_unificado[features_existentes + ['RISCO_DEFASAGEM']].dropna()\n",
    "print(f'\\nRegistros ap√≥s remover nulos: {len(df_modelo):,}')\n",
    "\n",
    "X = df_modelo[features_existentes].copy()\n",
    "y = df_modelo['RISCO_DEFASAGEM']\n",
    "\n",
    "# Criar feature derivada: m√©dia dos indicadores\n",
    "X['MEDIA_INDICADORES'] = X[features_existentes].mean(axis=1)\n",
    "\n",
    "print(f'\\nFeatures finais: {list(X.columns)}')\n",
    "print(f'Total de features: {len(X.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Separa√ß√£o dos Dados em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Manter propor√ß√£o das classes\n",
    ")\n",
    "\n",
    "print(f'üìä Divis√£o dos dados:')\n",
    "print(f'   Treino: {len(X_train):,} registros ({len(X_train)/len(X)*100:.0f}%)')\n",
    "print(f'   Teste: {len(X_test):,} registros ({len(X_test)/len(X)*100:.0f}%)')\n",
    "\n",
    "print(f'\\nDistribui√ß√£o da classe alvo no treino:')\n",
    "print(f'   Sem risco: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.1f}%)')\n",
    "print(f'   Com risco: {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Balanceamento com SMOTE\n",
    "\n",
    "Como temos um desbalanceamento significativo entre as classes (poucos alunos em risco), utilizamos a t√©cnica **SMOTE** (Synthetic Minority Over-sampling Technique) para criar exemplos sint√©ticos da classe minorit√°ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear as classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'üìä Ap√≥s aplicar SMOTE:')\n",
    "print(f'   Treino original: {len(X_train):,} registros')\n",
    "print(f'   Treino balanceado: {len(X_train_smote):,} registros')\n",
    "\n",
    "print(f'\\nDistribui√ß√£o ap√≥s SMOTE:')\n",
    "print(f'   Sem risco: {(y_train_smote == 0).sum():,} ({(y_train_smote == 0).mean()*100:.1f}%)')\n",
    "print(f'   Com risco: {(y_train_smote == 1).sum():,} ({(y_train_smote == 1).mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Normaliza√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('‚úÖ Dados normalizados com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Treinamento do Modelo (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo Random Forest\n",
    "modelo = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "modelo.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "print('‚úÖ Modelo Random Forest treinado com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√µes com threshold ajustado\n",
    "# Usamos threshold = 0.3 para priorizar o Recall (identificar mais alunos em risco)\n",
    "y_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
    "threshold = 0.3\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "# M√©tricas\n",
    "print('='*60)\n",
    "print(f'RESULTADOS DO MODELO (threshold={threshold})')\n",
    "print('='*60)\n",
    "print(f'   Acur√°cia:  {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'   Precis√£o:  {precision_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'   Recall:    {recall_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'   F1-Score:  {f1_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'   AUC-ROC:   {roc_auc_score(y_test, y_proba)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Sem Risco', 'Com Risco'],\n",
    "            yticklabels=['Sem Risco', 'Com Risco'])\n",
    "ax.set_xlabel('Predito', fontsize=12)\n",
    "ax.set_ylabel('Real', fontsize=12)\n",
    "ax.set_title('Matriz de Confus√£o', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nInterpreta√ß√£o:')\n",
    "print(f'   Verdadeiros Negativos (TN): {cm[0,0]} - Alunos sem risco corretamente identificados')\n",
    "print(f'   Falsos Positivos (FP): {cm[0,1]} - Alunos sem risco incorretamente classificados como em risco')\n",
    "print(f'   Falsos Negativos (FN): {cm[1,0]} - Alunos em risco n√£o identificados')\n",
    "print(f'   Verdadeiros Positivos (TP): {cm[1,1]} - Alunos em risco corretamente identificados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='#3498db', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random classifier')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "ax.set_ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "ax.set_title('Curva ROC', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('curva_roc.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Import√¢ncia das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import√¢ncia das features\n",
    "feature_names = list(X.columns)\n",
    "importances = modelo.feature_importances_\n",
    "\n",
    "# Ordenar por import√¢ncia\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print('üìä Import√¢ncia das Features:')\n",
    "print('='*40)\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f'{i+1}. {feature_names[idx]}: {importances[idx]*100:.1f}%')\n",
    "\n",
    "# Gr√°fico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.8, len(feature_names)))\n",
    "bars = ax.barh([feature_names[i] for i in indices], [importances[i] for i in indices], color=colors[::-1])\n",
    "ax.set_xlabel('Import√¢ncia', fontsize=12)\n",
    "ax.set_title('Import√¢ncia das Features no Modelo', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, imp in zip(bars, [importances[i] for i in indices]):\n",
    "    ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "            f'{imp*100:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Salvamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvar modelo e artefatos\n",
    "with open('modelo_risco_defasagem.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(feature_names))\n",
    "\n",
    "with open('threshold.txt', 'w') as f:\n",
    "    f.write(str(threshold))\n",
    "\n",
    "print('‚úÖ Modelo e artefatos salvos com sucesso!')\n",
    "print('   - modelo_risco_defasagem.pkl')\n",
    "print('   - scaler.pkl')\n",
    "print('   - features.txt')\n",
    "print('   - threshold.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclus√µes\n",
    "\n",
    "### Resultados do Modelo\n",
    "\n",
    "O modelo Random Forest treinado com dados dos 3 anos (2022-2024) apresentou os seguintes resultados:\n",
    "\n",
    "| M√©trica | Valor |\n",
    "|---------|-------|\n",
    "| **Acur√°cia** | 85.64% |\n",
    "| **Recall** | 65.38% |\n",
    "| **AUC-ROC** | 87.75% |\n",
    "| **F1-Score** | 37.36% |\n",
    "\n",
    "### Features Mais Importantes\n",
    "\n",
    "1. **IAN (Adequa√ß√£o ao N√≠vel)**: 29.9% - Principal preditor de risco\n",
    "2. **IPS (Psicossocial)**: 11.8%\n",
    "3. **MEDIA_INDICADORES**: 10.0%\n",
    "4. **IAA (Autoavalia√ß√£o)**: 10.0%\n",
    "5. **IPV (Ponto de Virada)**: 8.3%\n",
    "\n",
    "### Interpreta√ß√£o\n",
    "\n",
    "- O **AUC-ROC de 87.75%** indica excelente capacidade de discrimina√ß√£o entre alunos em risco e sem risco.\n",
    "- O **Recall de 65.38%** significa que o modelo identifica aproximadamente 2 em cada 3 alunos que realmente est√£o em risco.\n",
    "- O **IAN** √© o indicador mais importante, confirmando que a adequa√ß√£o ao n√≠vel √© o principal fator de risco.\n",
    "\n",
    "### Recomenda√ß√µes\n",
    "\n",
    "1. Utilizar o modelo como ferramenta de triagem para identificar alunos que necessitam de aten√ß√£o especial.\n",
    "2. Priorizar interven√ß√µes em alunos com IAN baixo.\n",
    "3. Monitorar indicadores psicossociais (IPS) e de autoavalia√ß√£o (IAA) como sinais de alerta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
